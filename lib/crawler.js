// Generated by CoffeeScript 1.9.3
(function() {
  var Crawler, EventEmitter, Queue, request, sleep, util,
    extend = function(child, parent) { for (var key in parent) { if (hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; },
    hasProp = {}.hasOwnProperty;

  EventEmitter = require('events').EventEmitter;

  util = require('util');

  request = require('request');

  Queue = require('./queue');

  sleep = require('sleep');

  Crawler = (function(superClass) {
    extend(Crawler, superClass);

    function Crawler(rateLimit, maxRequests) {
      if (rateLimit == null) {
        rateLimit = 10;
      }
      if (maxRequests == null) {
        maxRequests = 10;
      }
      this._rateLimit = rateLimit;
      this._maxRequests = maxRequests;
      this._nbRequests = 0;
      this._queue = new Queue();
      this._callback = function(error, response, body) {
        if (!error && response.statusCode === 200) {
          return console.log(body);
        } else {
          return console.log(error);
        }
      };
      this.on('queue_next', function() {
        var url;
        sleep.usleep(this._rateLimit);
        url = this._queue.pop();
        return this.crawl(url, this._callback);
      });
      this.on('queue_empty', function() {
        return console.log('Finish crawling. Queue is empty.');
      });
    }

    Crawler.prototype["do"] = function(callback) {

      /*
      Callback to be executed when url has been requested
       */
      this._callback = callback;
      return callback;
    };

    Crawler.prototype.queue = function(url) {

      /*
      Push an url in the queue to be crawled
       */
      this._queue.push(url);
      return url;
    };

    Crawler.prototype.next = function() {
      if (this._queue.size === 0) {
        sleep.usleep(this._rateLimit);
        this.emit('queue_next');
        return this.emit('queue_empty');
      }
    };

    Crawler.prototype.crawl = function(url, callback) {

      /*
      Request url and manage results in callback
       */
      return request(url, callback);
    };

    Crawler.prototype.start = function() {

      /*
      Will start crawling all urls in the queue
       */
      var results;
      results = [];
      while (this._nbRequests < this._maxRequests && this._queue.size > 0) {
        this.emit('queue_next');
        results.push(this._nbRequests++);
      }
      return results;
    };

    return Crawler;

  })(EventEmitter);

  module.exports = Crawler;

}).call(this);
